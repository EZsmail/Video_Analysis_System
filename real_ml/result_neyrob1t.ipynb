{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee929345",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install whisper -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyannote.audio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U openai-whisper -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d54f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scenedetect[opencv] opencv-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abeed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb694f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install imutils -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1c832168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Если каких-то библиотек нет, необходимо доустановить :)\n",
    "from transformers import GPT2Tokenizer, T5ForConditionalGeneration, AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from scenedetect import open_video, SceneManager\n",
    "from scenedetect.detectors import ContentDetector\n",
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment \n",
    "from pydub.silence import split_on_silence\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from moviepy.editor import VideoFileClip\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from ultralytics import YOLO, solutions\n",
    "from math import ceil\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import librosa\n",
    "import whisper\n",
    "import torch\n",
    "import spacy\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e05557df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in input_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Building video input_video.mp4.\n",
      "Moviepy - Writing video input_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready input_video.mp4\n"
     ]
    }
   ],
   "source": [
    "# Разделение видео и аудио\n",
    "def to_audio_and_clip(path:str) -> None:\n",
    "    input_video = VideoFileClip(path)\n",
    "    input_video.audio.write_audiofile('input_audio.mp3')\n",
    "    input_video.without_audio().write_videofile('input_video.mp4', codec='libx264')\n",
    "    \n",
    "to_audio_and_clip(r'C:\\Users\\frase\\OneDrive\\Рабочий стол\\test_obj_det_20sec.mp4') # Путь к файлу для разметки видео"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806756d",
   "metadata": {},
   "source": [
    "# Аудио"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8b8260e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'small' # На gpu можно выбрать модель base и выше\n",
    "model = whisper.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ee22335",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'input_audio.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "143d1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35aafdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание датасета под выходные данные модели whisper (если понадобятся дополнительные данные, то можно не удалять столбцы)\n",
    "df = pd.DataFrame(result['segments']).drop(['id', 'tokens', 'temperature', 'no_speech_prob', 'compression_ratio', 'avg_logprob', 'seek'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f91100",
   "metadata": {},
   "source": [
    "## Классификация звуков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9bedea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка аудиофайла\n",
    "def preprocess_audio(filename, target_sr=16000):\n",
    "    y, sr = librosa.load(filename, sr=None)  # Загружаем с оригинальной частотой\n",
    "    if sr != target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)  # Изменяем частоту\n",
    "    y = y / np.max(np.abs(y))  # Нормализация\n",
    "    return y, target_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f9fe9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классификация звука в аудиофрагментах\n",
    "def classification_audio(audio:list, threshold = 0.5):\n",
    "    model_url = \"https://tfhub.dev/google/yamnet/1\"\n",
    "    model = hub.load(model_url)\n",
    "    \n",
    "    result_classes = []\n",
    "    for i in range(len(audio)):\n",
    "        filename = audio[i]\n",
    "        y, sr = preprocess_audio(filename)\n",
    "        \n",
    "        scores, embeddings, spectrogram = model(y)\n",
    "        \n",
    "        # Определение классов звуковых событий\n",
    "        class_map_path = model.class_map_path().numpy().decode('utf-8')\n",
    "        class_names =list(pd.read_csv(class_map_path)['display_name'])\n",
    "        \n",
    "        top_k = 5 # Кол-во наиболее вероятных классов\n",
    "        \n",
    "        scores = scores.numpy() if tf.is_tensor(scores) else scores  # Преобразуем в numpy, если необходимо\n",
    "        \n",
    "        # Проверка на размерность\n",
    "        if len(scores.shape) > 1:\n",
    "            scores = scores[0]\n",
    "        \n",
    "        top_k_indices = np.argsort(scores)[-top_k:][::-1] # Сортируем и отбираем классы\n",
    "        \n",
    "        classes = [class_names[top_k_indices[0]]] # Первый обязательно добавляем в выбранные классы\n",
    "        \n",
    "        # Отбираем дополнительные возможные классы\n",
    "        for i in range(1, len(top_k_indices)):\n",
    "            if scores[top_k_indices[i]] > threshold:\n",
    "                classes.append(class_names[top_k_indices[i]])\n",
    "                \n",
    "        result_classes.append((filename, classes))\n",
    "    \n",
    "    return result_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36089797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбивка всего аудио на фрагменты\n",
    "def f(row):\n",
    "    audio = AudioSegment.from_file(audio_file)\n",
    "    start_time = row['start']*1000  # Начало обрезки в миллисекундах\n",
    "    end_time = row['end']*1000  # Конец обрезки в миллисекундах\n",
    "    if end_time - start_time <= 1000:\n",
    "        return 'underfind'\n",
    "    \n",
    "    trimmed_audio = audio[start_time:end_time]\n",
    "    trimmed_audio.export(\"output.mp3\", format=\"mp3\")\n",
    "    ans = classification_audio([\"output.mp3\"])\n",
    "    return ';'.join(ans[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ed87be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programs\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programs\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programs\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programs\\anaconda3\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['classifier_result'] = df.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057a5e0",
   "metadata": {},
   "source": [
    "## Определение спикеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "488c971c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:D:\\Programs\\anaconda3\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1808.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_for_speakers = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\",\n",
    "                                    use_auth_token=\"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\") # Токен одного из участников команды\n",
    "\n",
    "diarization = pipeline_for_speakers(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb13e1e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_speakers = pd.DataFrame(columns=['start', 'stop', 'speaker'])\n",
    "\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    df_speakers.loc[len(df_speakers)] = [turn.start, turn.end, speaker.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16a678da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируется отдельно, потому что сложно совместить с основным датасетом по аудио, из-за времени\n",
    "speakers_json = df_speakers.to_json(force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524df9fb",
   "metadata": {},
   "source": [
    "## Выделение смысла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64750621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1573e895f574651b5d9ed1fcf0fd7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_meaning = SentenceTransformer('sberbank-ai/sbert_large_nlu_ru')\n",
    "\n",
    "embeddings = model_meaning.encode(df['text'], batch_size=32, show_progress_bar=True)\n",
    "\n",
    "dbscan = DBSCAN(eps=0.4, min_samples=2, metric='cosine')\n",
    "labels = dbscan.fit_predict(embeddings)\n",
    "res = []\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    res.append(label)\n",
    "\n",
    "df['group meaning'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dab0b5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>classifier_result</th>\n",
       "      <th>group meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>9.28</td>\n",
       "      <td>Ровно 15 лет назад, 10 февраля 2007 года, Вла...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.28</td>\n",
       "      <td>15.48</td>\n",
       "      <td>по безопасности свою знаменитую речь, которую...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.48</td>\n",
       "      <td>21.68</td>\n",
       "      <td>объявлением новой холодной войны между Россие...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.68</td>\n",
       "      <td>28.36</td>\n",
       "      <td>обвинил США в попытках внедрить концепцию одн...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.36</td>\n",
       "      <td>35.84</td>\n",
       "      <td>прижения основополагающими принципами междуна...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.84</td>\n",
       "      <td>41.48</td>\n",
       "      <td>чуть ли не вся система права одного государст...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41.48</td>\n",
       "      <td>48.04</td>\n",
       "      <td>перешагнула свои национальные границы и по су...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.04</td>\n",
       "      <td>53.68</td>\n",
       "      <td>и в политике, и в гуманитарной сфере навязыва...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54.68</td>\n",
       "      <td>61.16</td>\n",
       "      <td>Среди слушателей в зале был и тогдашний прези...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61.16</td>\n",
       "      <td>67.24</td>\n",
       "      <td>что его самого и коллег из Странбалтии и Цент...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67.24</td>\n",
       "      <td>75.40</td>\n",
       "      <td>Мы услышали то, что на протяжении уже довольн...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75.40</td>\n",
       "      <td>81.60</td>\n",
       "      <td>просто на более низком политическом уровне. З...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>81.60</td>\n",
       "      <td>88.88</td>\n",
       "      <td>Помню, я сидел в зале рядом с сенатором Джоно...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>88.88</td>\n",
       "      <td>94.88</td>\n",
       "      <td>политики Москвы между теми, кто живет к Восто...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>94.88</td>\n",
       "      <td>102.64</td>\n",
       "      <td>В своем тогдашнем выступлении Путин раскритик...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>102.64</td>\n",
       "      <td>109.56</td>\n",
       "      <td>снижающим взаимное доверие. Получается, что Н...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>109.56</td>\n",
       "      <td>115.08</td>\n",
       "      <td>государственным границам. А мы строго выполня...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>115.08</td>\n",
       "      <td>124.16</td>\n",
       "      <td>И у нас есть справедливо право откровенно спр...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>124.16</td>\n",
       "      <td>132.08</td>\n",
       "      <td>заверениями, которые давались западными партн...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>132.08</td>\n",
       "      <td>138.36</td>\n",
       "      <td>эти заявления? Они даже никто не помнят. Одна...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>138.36</td>\n",
       "      <td>144.60</td>\n",
       "      <td>Хорс Тельчик, советник по внешней политике эк...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>144.60</td>\n",
       "      <td>150.96</td>\n",
       "      <td>ДВ Тельчик подчеркнул, что участвовал во всех...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>150.96</td>\n",
       "      <td>158.52</td>\n",
       "      <td>СССР Горбачевым и министром иностранных девуш...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>158.52</td>\n",
       "      <td>164.84</td>\n",
       "      <td>обещаний или обсуждений темы расширения НАТО....</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>164.84</td>\n",
       "      <td>171.52</td>\n",
       "      <td>было то, что после воссоединения Германии на ...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>171.52</td>\n",
       "      <td>179.52</td>\n",
       "      <td>кроме бундесвера, ни объектов НАТО. И это был...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>179.52</td>\n",
       "      <td>186.60</td>\n",
       "      <td>По мнению Тельчика, требование Кремля о нерас...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>186.60</td>\n",
       "      <td>192.40</td>\n",
       "      <td>Украина и Грузии неприемлемы. И российский пр...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>192.40</td>\n",
       "      <td>199.28</td>\n",
       "      <td>суверенное демократическое государство самост...</td>\n",
       "      <td>Speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     start     end                                               text  \\\n",
       "0     0.00    9.28   Ровно 15 лет назад, 10 февраля 2007 года, Вла...   \n",
       "1     9.28   15.48   по безопасности свою знаменитую речь, которую...   \n",
       "2    15.48   21.68   объявлением новой холодной войны между Россие...   \n",
       "3    21.68   28.36   обвинил США в попытках внедрить концепцию одн...   \n",
       "4    28.36   35.84   прижения основополагающими принципами междуна...   \n",
       "5    35.84   41.48   чуть ли не вся система права одного государст...   \n",
       "6    41.48   48.04   перешагнула свои национальные границы и по су...   \n",
       "7    48.04   53.68   и в политике, и в гуманитарной сфере навязыва...   \n",
       "8    54.68   61.16   Среди слушателей в зале был и тогдашний прези...   \n",
       "9    61.16   67.24   что его самого и коллег из Странбалтии и Цент...   \n",
       "10   67.24   75.40   Мы услышали то, что на протяжении уже довольн...   \n",
       "11   75.40   81.60   просто на более низком политическом уровне. З...   \n",
       "12   81.60   88.88   Помню, я сидел в зале рядом с сенатором Джоно...   \n",
       "13   88.88   94.88   политики Москвы между теми, кто живет к Восто...   \n",
       "14   94.88  102.64   В своем тогдашнем выступлении Путин раскритик...   \n",
       "15  102.64  109.56   снижающим взаимное доверие. Получается, что Н...   \n",
       "16  109.56  115.08   государственным границам. А мы строго выполня...   \n",
       "17  115.08  124.16   И у нас есть справедливо право откровенно спр...   \n",
       "18  124.16  132.08   заверениями, которые давались западными партн...   \n",
       "19  132.08  138.36   эти заявления? Они даже никто не помнят. Одна...   \n",
       "20  138.36  144.60   Хорс Тельчик, советник по внешней политике эк...   \n",
       "21  144.60  150.96   ДВ Тельчик подчеркнул, что участвовал во всех...   \n",
       "22  150.96  158.52   СССР Горбачевым и министром иностранных девуш...   \n",
       "23  158.52  164.84   обещаний или обсуждений темы расширения НАТО....   \n",
       "24  164.84  171.52   было то, что после воссоединения Германии на ...   \n",
       "25  171.52  179.52   кроме бундесвера, ни объектов НАТО. И это был...   \n",
       "26  179.52  186.60   По мнению Тельчика, требование Кремля о нерас...   \n",
       "27  186.60  192.40   Украина и Грузии неприемлемы. И российский пр...   \n",
       "28  192.40  199.28   суверенное демократическое государство самост...   \n",
       "\n",
       "   classifier_result  group meaning  \n",
       "0             Speech              0  \n",
       "1             Speech              0  \n",
       "2             Speech              0  \n",
       "3             Speech              0  \n",
       "4             Speech              0  \n",
       "5             Speech              0  \n",
       "6             Speech              0  \n",
       "7             Speech              0  \n",
       "8             Speech              0  \n",
       "9             Speech              0  \n",
       "10            Speech              0  \n",
       "11            Speech              0  \n",
       "12            Speech              0  \n",
       "13            Speech              0  \n",
       "14            Speech              0  \n",
       "15            Speech              0  \n",
       "16            Speech              0  \n",
       "17            Speech              0  \n",
       "18            Speech              0  \n",
       "19            Speech              0  \n",
       "20            Speech              0  \n",
       "21            Speech              0  \n",
       "22            Speech              0  \n",
       "23            Speech              0  \n",
       "24            Speech              0  \n",
       "25            Speech              0  \n",
       "26            Speech              0  \n",
       "27            Speech              0  \n",
       "28            Speech              0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a24102f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a2b24f6fa24da6ad03b98cbccc1804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(50364, 1536)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(50364, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 24)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(50364, 1536)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 24)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (k): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (v): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "              (o): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wi_1): Linear(in_features=1536, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50364, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('RussianNLP/FRED-T5-Summarizer',eos_token='</s>')\n",
    "model_meaning = T5ForConditionalGeneration.from_pretrained('RussianNLP/FRED-T5-Summarizer')\n",
    "device = 'cpu' # На gpu исполльзовать 'cuda'\n",
    "model_meaning.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e90d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def definition_of_meaning(text):\n",
    "    input_text = '''<LM> Напиши очень кратко одним предложением (сократи текст по смыслу), о чем говорится в тексте. Нельзя использовать слово \"текст\" в ответе.\\n''' + text\n",
    "    input_ids = torch.tensor([tokenizer.encode(input_text)]).to(device)\n",
    "    outputs = model_meaning.generate(input_ids,eos_token_id = tokenizer.eos_token_id,\n",
    "                        num_beams = 5,\n",
    "                        min_new_tokens = 17,\n",
    "                        max_new_tokens = 200,\n",
    "                        do_sample = True,\n",
    "                        no_repeat_ngram_size = 4,\n",
    "                        top_p = 0.9)\n",
    "    return tokenizer.decode(outputs[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a96c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_meaning = []\n",
    "\n",
    "step = 3 # Сколько подряд отрывков аудио брать для выделения в них смысла\n",
    "for i in range(0, len(df['text']) - step, step):\n",
    "    text = ''.join(list(df['text'].loc[i:i+step]))\n",
    "    res_sum = str(definition_of_meaning(text))[:-4]\n",
    "    for j in range(step):\n",
    "        text_meaning.append(res_sum)\n",
    "        \n",
    "k = len(df['text']) - len(text_meaning)\n",
    "text = ''.join(list(df['text'].loc[len(text_meaning):]))\n",
    "res_sum = str(definition_of_meaning(text))[:-4]\n",
    "\n",
    "for i in range(k):\n",
    "    text_meaning.append(res_sum)\n",
    "\n",
    "df['meaning'] = text_meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf25d6",
   "metadata": {},
   "source": [
    "## Проверка на стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2b36834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтения стоп слов из файла bad_word.txt\n",
    "def read_bad_words(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            bad_words = {line.strip().lower() for line in file if line.strip()}\n",
    "        return bad_words\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Файл '{file_path}' не найден.\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "14e1df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка наличия стоп слов в предложениях\n",
    "def check_bad_words_in_sentence(sentence, bad_words, nlp):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        lemma = token.lemma_.lower()\n",
    "        if lemma in bad_words:\n",
    "            return True, token.text, lemma\n",
    "    return False, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "643e2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('ru_core_news_sm')\n",
    "\n",
    "bad_words_file = 'bad_words.txt'\n",
    "bad_words = read_bad_words(bad_words_file)\n",
    "sentences = list(df['text'])\n",
    "bad_lines = []\n",
    "\n",
    "for idx, sentence in enumerate(sentences, start=1):\n",
    "    has_bad_word, word, lemma = check_bad_words_in_sentence(sentence, bad_words, nlp)\n",
    "    if has_bad_word:\n",
    "        bad_lines.append(idx)\n",
    "\n",
    "id_stop_words = np.array(['no'] * len(df))\n",
    "id_stop_words[bad_lines] = 'yes'\n",
    "df['stop words'] = id_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e718186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = df.to_json(force_ascii=False) # Конечный датасет с аудио"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e28ba",
   "metadata": {},
   "source": [
    "# Видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39637719",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = 'input_video.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4cd16c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смена сцен\n",
    "def scene_detector(path:str) -> list:\n",
    "    video = open_video(path)\n",
    "    scene_manager = SceneManager()\n",
    "    scene_manager.add_detector(ContentDetector())\n",
    "    scene_manager.detect_scenes(video)\n",
    "    scene_list = scene_manager.get_scene_list()\n",
    "    return scene_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "df0267de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сортировка слов\n",
    "def sort_words_by_position_with_tolerance(boxes, words, tolerance=10):\n",
    "    combined = list(zip(boxes, words))\n",
    "    \n",
    "    combined_sorted = sorted(combined, key=lambda item: (round(item[0][1] / tolerance), item[0][0]))\n",
    "    \n",
    "    sorted_boxes = [item[0] for item in combined_sorted]\n",
    "    sorted_words = [item[1] for item in combined_sorted]\n",
    "    \n",
    "    return sorted_boxes, sorted_words\n",
    "\n",
    "# Предобработка картинки\n",
    "def preprocess_image(image, target_size):\n",
    "    orig = image.copy()\n",
    "    \n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    (origH, origW) = image.shape[:2]\n",
    "    rW = origW / float(target_size[0])\n",
    "    rH = origH / float(target_size[1])\n",
    "    \n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    \n",
    "    return resized_image, orig, rW, rH\n",
    "\n",
    "def postprocess(scores, geometry, min_confidence):\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "    \n",
    "    for y in range(0, numRows):\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0, xData1, xData2, xData3 = geometry[0, 0:3 + 1, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "    \n",
    "        for x in range(0, numCols):\n",
    "            if scoresData[x] < min_confidence:\n",
    "                continue\n",
    "    \n",
    "            offsetX, offsetY = (x * 4.0, y * 4.0)\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            \n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "    \n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "            \n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])    \n",
    "    return rects, confidences\n",
    "\n",
    "def extract_text_from_region(image, startX, startY, endX, endY):\n",
    "    # Обрезаем регион изображения\n",
    "    image = image[startY:endY, startX:endX]\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.medianBlur(image, 3)\n",
    "    border = 150\n",
    "    image[image[:][:] > border] = 255\n",
    "    image[image[:][:] <= border] = 0\n",
    "    \n",
    "    text = re.sub(r'[^а-яё]', '', pytesseract.image_to_string(image, config='--oem 1 --psm 8', lang='rus').lower())\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def east_detect(image, net, target_size=(320, 192), min_confidence=0.6):\n",
    "    layerNames = [\n",
    "        \"feature_fusion/Conv_7/Sigmoid\",\n",
    "        \"feature_fusion/concat_3\"\n",
    "    ]\n",
    "    \n",
    "    resized_image, orig, rW, rH = preprocess_image(image, target_size)\n",
    "    (H, W) = resized_image.shape[:2]\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(resized_image, 1.0, (W, H),\n",
    "                                 (123.68, 116.78, 113.94), swapRB=False, crop=False)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    scores, geometry = net.forward(layerNames)\n",
    "    \n",
    "    rects, confidences = postprocess(scores, geometry, min_confidence)\n",
    "    \n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    padding = 8\n",
    "    text = []\n",
    "    boxes_r = []\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        startX = max(0, int(startX * rW) - padding)\n",
    "        startY = max(0, int(startY * rH) - padding)\n",
    "        endX = min(orig.shape[1], int(endX * rW) + padding)\n",
    "        endY = min(orig.shape[0], int(endY * rH) + padding)\n",
    "        \n",
    "        #cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 1)\n",
    "        text_tmp = extract_text_from_region(image, startX, startY, endX, endY)\n",
    "        if len(text_tmp) >= 3:\n",
    "            boxes_r.append([startX, startY, endX, endY])\n",
    "            text.append(text_tmp)\n",
    "        \n",
    "    \n",
    "    boxes_r, text  = sort_words_by_position_with_tolerance(boxes_r, text, tolerance=30)\n",
    "    print(f\"Time taken: {time.time() - start:.4f} seconds\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e226397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение текста с картинки\n",
    "def get_text_for_video(path:str, frame_step=60) -> list:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    assert cap.isOpened()\n",
    "    results = []\n",
    "    frame_count = 0\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    net = cv2.dnn.readNet(\"model/frozen_east_text_detection.pb\")\n",
    "    for frame_id in range(0, total_frames, frame_step):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        ret, frame = cap.read()\n",
    "        print(f\"Обрабатываем кадр {frame_id + 1} ({(frame_id // frame_step) + 1})\", end='    ')\n",
    "        results.append(east_detect(frame, net, (32 * 24, 32 * 14), 0.7))\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return results, frame_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd091458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обрабатываем кадр 1 (1)    Time taken: 2.6617 seconds\n",
      "Обрабатываем кадр 61 (2)    Time taken: 2.0148 seconds\n",
      "Обрабатываем кадр 121 (3)    Time taken: 1.9373 seconds\n",
      "Обрабатываем кадр 181 (4)    Time taken: 1.7346 seconds\n",
      "Обрабатываем кадр 241 (5)    Time taken: 1.8788 seconds\n",
      "Обрабатываем кадр 301 (6)    Time taken: 1.8154 seconds\n",
      "Обрабатываем кадр 361 (7)    Time taken: 1.8382 seconds\n",
      "Обрабатываем кадр 421 (8)    Time taken: 1.8142 seconds\n",
      "Обрабатываем кадр 481 (9)    Time taken: 1.8591 seconds\n",
      "Обрабатываем кадр 541 (10)    Time taken: 1.8480 seconds\n"
     ]
    }
   ],
   "source": [
    "results = get_text_for_video(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b2bc78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка слов с видео на стоп слова\n",
    "stop_words_in_video = pd.DataFrame(columns=['framerate', 'stop words'])\n",
    "\n",
    "for i in range(len(results[0])):\n",
    "    if len(results[0][i]) > 0:\n",
    "        sentences = results[0]\n",
    "        bad_lines = []\n",
    "\n",
    "        for idx, sentence in enumerate(sentences, start=1):\n",
    "            has_bad_word, word, lemma = check_bad_words_in_sentence(sentence, bad_words, nlp)\n",
    "            if has_bad_word:\n",
    "                bad_lines.append(idx)\n",
    "        \n",
    "        if len(has_bad_word) > 0:\n",
    "            stop_words_in_video.loc[len(stop_words_in_video)] = [i * results[1] + 1, 'yes']\n",
    "        else:\n",
    "            stop_words_in_video.loc[len(stop_words_in_video)] = [i * results[1] + 1, 'no']\n",
    "    else:\n",
    "        stop_words_in_video.loc[len(stop_words_in_video)] = [i * results[1] + 1, 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e03317a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка на nsfw контент\n",
    "def check_nsfw_on_video(path, frame_step=60):\n",
    "    classifier = pipeline(\"image-classification\", model=\"Falconsai/nsfw_image_detection\")\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    assert cap.isOpened()\n",
    "\n",
    "    frame_count = 0\n",
    "    result = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    for frame_id in range(0, total_frames, frame_step):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = Image.fromarray(frame)\n",
    "        verdict = classifier(frame)\n",
    "        if verdict[0]['label'] == 'nsfw':\n",
    "            result.append(verdict[0]['score'])\n",
    "        else:\n",
    "            result.append(verdict[1]['score'])\n",
    "        \n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f9e76bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация тепловых карт\n",
    "def heat_map(path:str) -> None:\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "    video_writer = cv2.VideoWriter(\"heatmap_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    heatmap_obj = solutions.Heatmap(\n",
    "        colormap=cv2.COLORMAP_PARULA,\n",
    "        view_img=False,\n",
    "        shape=\"circle\",\n",
    "        names=model.names,\n",
    "    )\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, im0 = cap.read()\n",
    "        if not success:\n",
    "            print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "            break\n",
    "\n",
    "        tracks = model.track(im0, persist=True, show=False)\n",
    "\n",
    "        im0 = heatmap_obj.generate_heatmap(im0, tracks)\n",
    "\n",
    "        video_writer.write(im0)\n",
    "\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d07b70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обнаружение объектов\n",
    "def obj_detection(path) -> None:\n",
    "    track_history = defaultdict(lambda: [])\n",
    "\n",
    "    model = YOLO(\"yolov8n-seg.pt\")  # segmentation model\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "    out = cv2.VideoWriter(\"instance-segmentation-object-tracking.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), fps, (w, h))\n",
    "\n",
    "    while True:\n",
    "        ret, im0 = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "            break\n",
    "\n",
    "        annotator = Annotator(im0, line_width=2)\n",
    "\n",
    "        results = model.track(im0, persist=True)\n",
    "\n",
    "        if results[0].boxes.id is not None and results[0].masks is not None:\n",
    "            masks = results[0].masks.xy\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "            for mask, track_id in zip(masks, track_ids):\n",
    "                color = colors(int(track_id), True)\n",
    "                txt_color = annotator.get_txt_color(color)\n",
    "                annotator.seg_bbox(mask=mask, mask_color=color, label=str(track_id), txt_color=txt_color)\n",
    "\n",
    "        out.write(im0)\n",
    "\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bcfc55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nswf = check_nsfw_on_video(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "744a52da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nswf = ['%.2f' % elem for elem in nswf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08cdbbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nswf_in_video = pd.DataFrame({'framerate': [i + 1 for i in range(0, len(nswf) * 60, 60)], 'nswf': nswf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "991c5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = pd.merge(nswf_in_video, stop_words_in_video, on='framerate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bb92d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_json = video.to_json(force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42a73244",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_json = {'audio': df_json, 'spekears': speakers_json, 'video': video_json}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "741d9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(res_json, ensure_ascii=False)\n",
    " \n",
    "with open('result.json', 'w', encoding='utf-8') as file:\n",
    "    file.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
