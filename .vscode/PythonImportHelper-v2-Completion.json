[
    {
        "label": "pika",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pika",
        "description": "pika",
        "detail": "pika",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "psycopg2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psycopg2",
        "description": "psycopg2",
        "detail": "psycopg2",
        "documentation": {}
    },
    {
        "label": "execute_values",
        "importPath": "psycopg2.extras",
        "description": "psycopg2.extras",
        "isExtraImport": true,
        "detail": "psycopg2.extras",
        "documentation": {}
    },
    {
        "label": "connection",
        "kind": 5,
        "importPath": "ml.test_send",
        "description": "ml.test_send",
        "peekOfCode": "connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost', port=5672))\nchannel = connection.channel()\nchannel.queue_declare(queue='video_processing')\nmessage = {\n    \"processing_id\": \"12345\",\n    \"file_path\": \"/path/to/video.mp4\"\n}\nchannel.basic_publish(\n    exchange='',\n    routing_key='video_processing',",
        "detail": "ml.test_send",
        "documentation": {}
    },
    {
        "label": "channel",
        "kind": 5,
        "importPath": "ml.test_send",
        "description": "ml.test_send",
        "peekOfCode": "channel = connection.channel()\nchannel.queue_declare(queue='video_processing')\nmessage = {\n    \"processing_id\": \"12345\",\n    \"file_path\": \"/path/to/video.mp4\"\n}\nchannel.basic_publish(\n    exchange='',\n    routing_key='video_processing',\n    body=json.dumps(message),",
        "detail": "ml.test_send",
        "documentation": {}
    },
    {
        "label": "message",
        "kind": 5,
        "importPath": "ml.test_send",
        "description": "ml.test_send",
        "peekOfCode": "message = {\n    \"processing_id\": \"12345\",\n    \"file_path\": \"/path/to/video.mp4\"\n}\nchannel.basic_publish(\n    exchange='',\n    routing_key='video_processing',\n    body=json.dumps(message),\n)\nprint(\"Sent task:\", message)",
        "detail": "ml.test_send",
        "documentation": {}
    },
    {
        "label": "process_video",
        "kind": 2,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "def process_video(file_path):\n    print(f\"Processing video: {file_path}\")\n    time.sleep(5)\n    return [[\"Part 1\", \"00:00\", \"00:30\"], [\"Part 2\", \"00:31\", \"01:00\"]]\ndef save_csv(processing_id, csv_data):\n    output_file = f\"{processing_id}.csv\"\n    with open(output_file, mode=\"w\", newline=\"\") as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Part\", \"Start time\", \"End time\"])\n        writer.writerows(csv_data)",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "save_csv",
        "kind": 2,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "def save_csv(processing_id, csv_data):\n    output_file = f\"{processing_id}.csv\"\n    with open(output_file, mode=\"w\", newline=\"\") as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Part\", \"Start time\", \"End time\"])\n        writer.writerows(csv_data)\n    print(f\"Saved CSV: {output_file}\")\ndef update_status_in_postgresql(processing_id, status):\n    query = \"UPDATE processing_status SET status = %s WHERE processing_id = %s\"\n    pg_cursor.execute(query, (status, processing_id))",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "update_status_in_postgresql",
        "kind": 2,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "def update_status_in_postgresql(processing_id, status):\n    query = \"UPDATE processing_status SET status = %s WHERE processing_id = %s\"\n    pg_cursor.execute(query, (status, processing_id))\n    pg_connection.commit()\n    print(f\"Updated status for {processing_id} to {status}\")\ndef save_results_to_mongodb(processing_id, csv_data):\n    document = {\n        \"_id\": processing_id,\n        \"result_path\": csv_data\n    }",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "save_results_to_mongodb",
        "kind": 2,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "def save_results_to_mongodb(processing_id, csv_data):\n    document = {\n        \"_id\": processing_id,\n        \"result_path\": csv_data\n    }\n    collection_results.replace_one({\"_id\": processing_id}, document, upsert=True)\n    print(f\"Saved results to MongoDB for {processing_id}\")\ndef on_message(channel, method, properties, body):\n    message = json.loads(body)\n    processing_id = message[\"processing_id\"]",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "on_message",
        "kind": 2,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "def on_message(channel, method, properties, body):\n    message = json.loads(body)\n    processing_id = message[\"processing_id\"]\n    file_path = message[\"file_path\"]\n    print(f\"Received task: {processing_id} - {file_path}\")\n    try:\n        update_status_in_postgresql(processing_id, \"processing\")\n        csv_data = process_video(file_path)\n        save_results_to_mongodb(processing_id, csv_data)\n        save_csv(processing_id, csv_data)",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "mongo_client",
        "kind": 5,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "mongo_client = MongoClient(\"mongodb://localhost:27017\")\nmongo_db = mongo_client[\"video_processing_db\"]\ncollection_results = mongo_db[\"collection_results\"]\npg_connection = psycopg2.connect(\n    dbname=\"video_processing_db\",\n    user=\"postgres\",\n    password=\"password\",\n    host=\"localhost\",\n    port=5440\n)",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "mongo_db",
        "kind": 5,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "mongo_db = mongo_client[\"video_processing_db\"]\ncollection_results = mongo_db[\"collection_results\"]\npg_connection = psycopg2.connect(\n    dbname=\"video_processing_db\",\n    user=\"postgres\",\n    password=\"password\",\n    host=\"localhost\",\n    port=5440\n)\npg_cursor = pg_connection.cursor()",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "collection_results",
        "kind": 5,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "collection_results = mongo_db[\"collection_results\"]\npg_connection = psycopg2.connect(\n    dbname=\"video_processing_db\",\n    user=\"postgres\",\n    password=\"password\",\n    host=\"localhost\",\n    port=5440\n)\npg_cursor = pg_connection.cursor()\ndef process_video(file_path):",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "pg_connection",
        "kind": 5,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "pg_connection = psycopg2.connect(\n    dbname=\"video_processing_db\",\n    user=\"postgres\",\n    password=\"password\",\n    host=\"localhost\",\n    port=5440\n)\npg_cursor = pg_connection.cursor()\ndef process_video(file_path):\n    print(f\"Processing video: {file_path}\")",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "pg_cursor",
        "kind": 5,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "pg_cursor = pg_connection.cursor()\ndef process_video(file_path):\n    print(f\"Processing video: {file_path}\")\n    time.sleep(5)\n    return [[\"Part 1\", \"00:00\", \"00:30\"], [\"Part 2\", \"00:31\", \"01:00\"]]\ndef save_csv(processing_id, csv_data):\n    output_file = f\"{processing_id}.csv\"\n    with open(output_file, mode=\"w\", newline=\"\") as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Part\", \"Start time\", \"End time\"])",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "connection",
        "kind": 5,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "connection = pika.BlockingConnection(pika.ConnectionParameters(host=\"localhost\", port=\"5672\"))\nchannel = connection.channel()\nchannel.queue_declare(queue=\"video_processing\")\nchannel.basic_consume(queue=\"video_processing\", on_message_callback=on_message)\nprint(\"Waiting for messages...\")\nchannel.start_consuming()",
        "detail": "ml.worker",
        "documentation": {}
    },
    {
        "label": "channel",
        "kind": 5,
        "importPath": "ml.worker",
        "description": "ml.worker",
        "peekOfCode": "channel = connection.channel()\nchannel.queue_declare(queue=\"video_processing\")\nchannel.basic_consume(queue=\"video_processing\", on_message_callback=on_message)\nprint(\"Waiting for messages...\")\nchannel.start_consuming()",
        "detail": "ml.worker",
        "documentation": {}
    }
]